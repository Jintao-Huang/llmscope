# 推理和部署

以下为swift支持的推理引擎以及接入部分的相应能力，三种推理加速引擎为SWIFT的推理、部署、评测模块提供推理加速：

| 推理加速引擎 | OpenAI API | 多模态 |  量化模型 | 多LoRA | QLoRA | Batch推理 | 并行技术       |
| ------------ | -------------- | ---------- | ------ | -------- | ------ | ----- | ----- |
| pytorch      | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/deploy/client/llm/chat/openai_client.py) | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/app/mllm.sh) |     ✅        | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/infer/demo_lora.py) | ✅     | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/batch_ddp.sh) |DDP/device_map |
| [vllm](https://github.com/vllm-project/vllm)         | ✅          | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/infer/vllm/mllm_tp.sh) |    ✅        | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/deploy/lora/server.sh) | ❌    | ✅ |  TP/PP   |
| [lmdeploy](https://github.com/InternLM/lmdeploy)    | ✅          | [✅](https://github.com/modelscope/ms-swift/blob/main/examples/infer/lmdeploy/mllm_tp.sh) |      ✅        | ❌      | ❌     | ✅ | TP     |


## 推理
ms-swift使用了分层式的设计思想，用户可以使用命令行界面、Web-UI界面和直接使用Python的方式进行推理。

### 使用CLI

全参数模型：
```shell
CUDA_VISIBLE_DEVICES=0 swift infer \
    --model Qwen/Qwen2.5-7B-Instruct \
    --stream true \
    --infer_backend pt \
    --max_new_tokens 2048
```

LoRA模型：
```shell
CUDA_VISIBLE_DEVICES=0 swift infer \
    --model Qwen/Qwen2.5-7B-Instruct \
    --adapters swift/test_lora \
    --stream true \
    --infer_backend pt \
    --temperature 0 \
    --max_new_tokens 2048
```


数据集推理：
```shell
CUDA_VISIBLE_DEVICES=0 swift infer \
    --model Qwen/Qwen2.5-7B-Instruct \
    --stream true \
    --infer_backend pt \
    --val_dataset AI-ModelScope/alpaca-gpt4-data-zh \
    --max_new_tokens 2048
```

以上提供了全参数和LoRA流式推理的例子，以下介绍更多SWIFT中的推理技术：
- 界面推理：你可以将`swift infer`改成`swift app`
- batch推理：`infer_backend=pt`可以指定`--max_batch_size`对大模型和多模态大模型进行batch推理，具体参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/batch_ddp.sh)。在进行batch推理时，你不能设置`--stream true`。
- DDP/device_map推理：`infer_backend=pt`支持使用DDP/device_map技术进行并行推理，具体参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/mllm_device_map.sh)。
- 推理加速：swift支持使用vllm/lmdeploy对推理、部署和评测模块进行推理加速，只需要额外指定`--infer_backend vllm/lmdeploy`即可。
- 多模态模型：我们提供了[pt](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/mllm_device_map.sh)/[vllm](https://github.com/modelscope/ms-swift/blob/main/examples/infer/vllm/mllm_tp.sh)/[lmdeploy](https://github.com/modelscope/ms-swift/blob/main/examples/infer/lmdeploy/mllm_tp.sh)对多模态模型进行多GPU推理的shell脚本。
- 量化模型：直接选择GPTQ、AWQ、BNB量化的模型，例如：`--model Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4`即可。
- 更多模型类型：我们提供了[bert](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/bert.sh)、[reward_model](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/reward_model.sh)、[prm](https://github.com/modelscope/ms-swift/blob/main/examples/infer/pt/prm.sh)的推理脚本


小帖士：
- SWIFT会将推理结果保存起来，你可以通过`--result_path`指定保存路径
- 如果要输出logprobs，只需要在推理时，指定`--logprobs true`即可。SWIFT会保存。注意，设置`--stream true`将不会存储
- 使用`--infer_backend vllm`出现OOM，可以通过降低`--max_model_len`，`--max_num_seqs`，选择合适的`--gpu_memory_utilization`，设置`--enforce_eager true`。或者使用tensor并行`--tensor_parallel_size`来解决。
- 使用`--infer_backend vllm`推理多模态模型，需要传入多张图片。可以设置`--limit_mm_per_prompt`解决，例如：`--limit_mm_per_prompt '{"image": 5, "video": 2}'`。
- 推理qwen2-vl/qwen2.5-vl出现OOM，可以通过设置`MAX_PIXELS`、`VIDEO_MAX_PIXELS`、`FPS_MAX_FRAMES`解决，可以参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/app/mllm.sh)。


### 使用Web-UI


### 使用Python


- grounding任务：对多模态模型进行Grounding任务画框，可以参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/demo_grounding.py)
- 多LoRA推理：
- agent推理：参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/demo_agent.py)。

SWIFT支持以命令行、Python代码和界面方式进行推理和部署：
- 使用`engine.infer`或者`engine.infer_async`进行python的方式推理. 参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/demo.py).
- 使用`swift infer`使用命令行的方式进行推理. 参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/infer/cli_demo.sh).
- 使用`swift deploy`进行服务部署，并使用openai API或者`client.infer`的方式推理. 服务端参考[这里](https://github.com/modelscope/ms-swift/tree/main/examples/deploy/server), 客户端参考[这里](https://github.com/modelscope/ms-swift/tree/main/examples/deploy/client).
- 使用`swift app`部署模型进行界面推理, 可以查看[这里](../GetStarted/Web-UI.md)



**命令行推理指令**

命令行推理可以参考上述第二点给出的链接。脚本运行后仅需在terminal中输入query即可。注意命令行的几个使用方式：
- `reset-system`命令 重置system
- `multi-line`命令 切换到多行模式，在输入中支持换行输入，以`#`代表输入结束
- `single-line`命令 切换到单行模式
- `clear`命令 清除history
- `exit`命令 退出
- 如果query中带有多模态数据，添加`<image>/<video>/<audio>`等标签，例如输入`<image>What is in the image?`，即可在接下来输入图片地址



## 部署




##

可以使用`swift infer/deploy`执行推理和部署。目前SWIFT支持pt（原生torch）、vLLM、LMDeploy三种推理框架，分别可以用`--infer_backend pt/vllm/lmdeploy`进行切换。
除pt外，vllm和lmdeploy分别有自己的模型支持范围，请查看各自官方文档来确定是否可用，以防出现运行错误。
